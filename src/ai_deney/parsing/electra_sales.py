"""Parsing + normalization helpers for Electra sales fixtures."""

from __future__ import annotations

import csv
import re
from pathlib import Path

from ai_deney.adapters.electra_adapter import parse_electra_export

NORMALIZED_COLUMNS = [
    "date",
    "year",
    "agency_id",
    "agency_name",
    "gross_sales",
    "net_sales",
    "currency",
]

TOTAL_AGENCY_ID = "TOTAL"
TOTAL_AGENCY_NAME = "Overall Total"

_PDF_ROW_RE = re.compile(
    r"(\d{4}-\d{2}-\d{2})\|([0-9]+(?:\.[0-9]+)?)\|([0-9]+(?:\.[0-9]+)?)\|([A-Z]{3})"
)


def parse_sales_summary_csv(path: Path) -> list[dict]:
    """Parse ``sales_summary_<year>.csv`` fixture rows."""
    rows: list[dict] = []
    for row in parse_electra_export(path, report_type="sales_summary"):
        date = row["date"].strip()
        year = int(date.split("-", 1)[0])
        rows.append(
            {
                "date": date,
                "year": year,
                "agency_id": TOTAL_AGENCY_ID,
                "agency_name": TOTAL_AGENCY_NAME,
                "gross_sales": float(row["gross_sales"]),
                "net_sales": float(row.get("net_sales", "") or 0.0),
                "currency": (row.get("currency") or "USD").strip() or "USD",
            }
        )
    return rows


def parse_sales_by_agency_csv(path: Path) -> list[dict]:
    """Parse ``sales_by_agency_<year>.csv`` fixture rows."""
    rows: list[dict] = []
    for row in parse_electra_export(path, report_type="sales_by_agency"):
        date = row["date"].strip()
        year = int(date.split("-", 1)[0])
        rows.append(
            {
                "date": date,
                "year": year,
                "agency_id": row["agency_id"].strip(),
                "agency_name": row["agency_name"].strip(),
                "gross_sales": float(row["gross_sales"]),
                "net_sales": float(row.get("net_sales", "") or 0.0),
                "currency": (row.get("currency") or "USD").strip() or "USD",
            }
        )
    return rows


def parse_sales_summary_pdf(path: Path) -> list[dict]:
    """
    Parse deterministic sample PDF generated by ``scripts/make_fixture_pdf.py``.

    The parser scans raw PDF text streams for pipe-delimited table rows.
    """
    text = path.read_bytes().decode("latin-1", errors="ignore")
    rows: list[dict] = []
    for date, gross, net, currency in _PDF_ROW_RE.findall(text):
        rows.append(
            {
                "date": date,
                "year": int(date.split("-", 1)[0]),
                "agency_id": TOTAL_AGENCY_ID,
                "agency_name": TOTAL_AGENCY_NAME,
                "gross_sales": float(gross),
                "net_sales": float(net),
                "currency": currency.strip() or "USD",
            }
        )
    return rows


def parse_report_file(path: Path, report_type: str) -> list[dict]:
    """Parse a single report file to normalized records."""
    suffix = path.suffix.lower()
    if suffix in {".csv", ".xlsx", ".xlsm"}:
        if report_type == "sales_summary":
            return parse_sales_summary_csv(path)
        if report_type == "sales_by_agency":
            return parse_sales_by_agency_csv(path)
    if suffix == ".pdf" and report_type == "sales_summary":
        return parse_sales_summary_pdf(path)
    raise ValueError(f"unsupported report file: {path} for report_type={report_type}")


def _dedupe_rows(rows: list[dict]) -> list[dict]:
    seen = set()
    out: list[dict] = []
    for row in rows:
        key = tuple(str(row[c]) for c in NORMALIZED_COLUMNS)
        if key in seen:
            continue
        seen.add(key)
        out.append(row)
    return out


def write_normalized_yearly(records: list[dict], output_root: Path) -> list[Path]:
    """
    Write/update deterministic normalized yearly CSVs.

    Existing files are merged and de-duplicated by full row content.
    """
    output_root.mkdir(parents=True, exist_ok=True)
    years = sorted({int(r["year"]) for r in records})
    out_paths: list[Path] = []
    for year in years:
        year_rows = [r for r in records if int(r["year"]) == year]
        out_path = output_root / f"electra_sales_{year}.csv"

        merged_rows: list[dict] = []
        if out_path.exists():
            with out_path.open("r", encoding="utf-8", newline="") as f:
                for row in csv.DictReader(f):
                    merged_rows.append(
                        {
                            "date": row["date"],
                            "year": int(row["year"]),
                            "agency_id": row["agency_id"],
                            "agency_name": row["agency_name"],
                            "gross_sales": float(row["gross_sales"]),
                            "net_sales": float(row.get("net_sales", "") or 0.0),
                            "currency": row.get("currency", "USD") or "USD",
                        }
                    )

        merged_rows.extend(year_rows)
        merged_rows = _dedupe_rows(merged_rows)
        merged_rows.sort(key=lambda r: (r["date"], r["agency_id"], r["agency_name"]))

        with out_path.open("w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=NORMALIZED_COLUMNS)
            writer.writeheader()
            for row in merged_rows:
                writer.writerow(
                    {
                        "date": row["date"],
                        "year": int(row["year"]),
                        "agency_id": row["agency_id"],
                        "agency_name": row["agency_name"],
                        "gross_sales": f"{float(row['gross_sales']):.2f}",
                        "net_sales": f"{float(row['net_sales']):.2f}",
                        "currency": row.get("currency", "USD") or "USD",
                    }
                )
        out_paths.append(out_path)
    return out_paths


def normalize_report_files(report_paths: list[Path], report_type: str, output_root: Path) -> list[Path]:
    """Parse one report batch and write normalized yearly CSV files."""
    records: list[dict] = []
    for path in report_paths:
        records.extend(parse_report_file(path, report_type=report_type))
    return write_normalized_yearly(records, output_root=output_root)
